{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure: Water Pump Preprocessor\n",
    "Below is a class that wraps your entire logic in method-based steps, along with a run_all() method to execute the full pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "class WaterPumpPreprocessor:\n",
    "    def __init__(self, df, gadm_path=None):\n",
    "        self.df = df.copy()\n",
    "        self.gadm_path = gadm_path\n",
    "\n",
    "    def impute_coords_from_shapefile(self, score_threshold=80):\n",
    "        if self.gadm_path is None:\n",
    "            raise ValueError(\"GADM shapefile path must be provided.\")\n",
    "\n",
    "        wards_gdf = gpd.read_file(self.gadm_path)\n",
    "        wards_gdf.rename(columns={'NAME_3': 'ward', 'NAME_2': 'district'}, inplace=True)\n",
    "        self.df['ward_clean'] = self.df['ward'].astype(str).str.lower()\n",
    "        wards_gdf['ward_clean'] = wards_gdf['ward'].astype(str).str.lower()\n",
    "\n",
    "        self.df['latitude'] = self.df['latitude'].replace([-2e-08, 0.0], pd.NA)\n",
    "        self.df['longitude'] = self.df['longitude'].replace([0.0], pd.NA)\n",
    "\n",
    "        df_valid = self.df[self.df['latitude'].notna() & self.df['longitude'].notna()]\n",
    "        df_missing = self.df[self.df['latitude'].isna() | self.df['longitude'].isna()]\n",
    "\n",
    "        matches = []\n",
    "        for ward in df_missing['ward_clean'].unique():\n",
    "            match, score, _ = process.extractOne(\n",
    "                query=ward, choices=wards_gdf['ward_clean'], scorer=fuzz.token_sort_ratio\n",
    "            )\n",
    "            matches.append({'ward_clean': ward, 'matched_ward': match, 'score': score})\n",
    "        match_df = pd.DataFrame(matches)\n",
    "        match_df = match_df[match_df['score'] >= score_threshold]\n",
    "\n",
    "        df_missing = df_missing.merge(match_df, on='ward_clean', how='left')\n",
    "        wards_unique = wards_gdf.drop_duplicates(subset=['ward_clean'])\n",
    "\n",
    "        df_missing = df_missing.merge(\n",
    "            wards_unique[['ward_clean', 'geometry']],\n",
    "            left_on='matched_ward', right_on='ward_clean', how='left'\n",
    "        )\n",
    "\n",
    "        def get_centroid_coords(geom):\n",
    "            if geom and not geom.is_empty:\n",
    "                return pd.Series([geom.centroid.y, geom.centroid.x])\n",
    "            return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "        df_missing[['latitude', 'longitude']] = df_missing['geometry'].apply(get_centroid_coords)\n",
    "\n",
    "        self.df = pd.concat([df_valid, df_missing], ignore_index=True)\n",
    "\n",
    "    def impute_subvillage_by_location(self):\n",
    "        known = self.df[self.df['subvillage'].notnull()]\n",
    "        unknown = self.df[self.df['subvillage'].isnull()]\n",
    "\n",
    "        if not unknown.empty and not known.empty:\n",
    "            nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "            nn.fit(known[['latitude', 'longitude']])\n",
    "            distances, indices = nn.kneighbors(unknown[['latitude', 'longitude']])\n",
    "            self.df.loc[unknown.index, 'subvillage'] = known.iloc[indices.flatten()]['subvillage'].values\n",
    "\n",
    "    def fuzzy_clean_column(self, column, top_n=50, threshold=75, force_include=None):\n",
    "        def clean_text(val):\n",
    "            val = str(val).lower().strip()\n",
    "            return re.sub(r'[^a-z0-9\\s]', '', val)\n",
    "\n",
    "        col_clean = f\"{column}_clean\"\n",
    "        col_grouped = f\"{column}_grouped\"\n",
    "\n",
    "        self.df[column] = self.df[column].fillna(\"missing\")\n",
    "        self.df[col_clean] = self.df[column].astype(str).apply(clean_text)\n",
    "\n",
    "        top_values = self.df[col_clean].value_counts().head(top_n).index.tolist()\n",
    "        if force_include:\n",
    "            top_values += force_include\n",
    "            top_values = list(set(top_values))\n",
    "\n",
    "        def match_func(val):\n",
    "            result = process.extractOne(val, top_values, scorer=fuzz.ratio)\n",
    "            if result and result[1] >= threshold:\n",
    "                return result[0]\n",
    "            return val\n",
    "\n",
    "        self.df[col_grouped] = self.df[col_clean].apply(match_func)\n",
    "\n",
    "    def combine_funder_installer_grouped(self):\n",
    "        self.fuzzy_clean_column(\"installer\", force_include=[\"hesawa\", \"government\", \"unicef\", \"jica\", \"rc church\", \"danida\"])\n",
    "        self.fuzzy_clean_column(\"funder\", force_include=[\"hesawa\", \"government\", \"unicef\", \"jica\", \"rc church\", \"danida\"])\n",
    "\n",
    "        def group_names(x):\n",
    "            x = str(x).lower()\n",
    "            if 'gov' in x: return 'government'\n",
    "            if 'japan' in x or x in ['jica', 'jaica']: return 'japan'\n",
    "            if 'german' in x: return 'germany'\n",
    "            if 'village' in x: return 'village'\n",
    "            return x\n",
    "\n",
    "        self.df['installer_grouped'] = self.df['installer_grouped'].apply(group_names)\n",
    "        self.df['funder_grouped'] = self.df['funder_grouped'].apply(group_names)\n",
    "\n",
    "        self.df['installer_grouped'] = self.df['installer_grouped'].replace({'danid': 'danida', 'commu': 'community', '0': 'unknown'})\n",
    "        self.df['funder_grouped'] = self.df['funder_grouped'].replace({\n",
    "            'fini water': 'ministry of water',\n",
    "            '0': 'unknown',\n",
    "            'germany republi': 'germany',\n",
    "            'adb': 'african development bank'\n",
    "        })\n",
    "\n",
    "        self.df['funder_installer_grouped'] = self.df['funder_grouped'] + \"_\" + self.df['installer_grouped']\n",
    "        rare = self.df['funder_installer_grouped'].value_counts()[lambda x: x < 10].index\n",
    "        self.df['funder_installer_pair_grouped'] = self.df['funder_installer_grouped'].apply(lambda x: x if x not in rare else 'other')\n",
    "\n",
    "        self.df.drop(columns=['funder_clean', 'installer_clean', 'funder', 'installer', 'funder_installer_grouped'], inplace=True)\n",
    "\n",
    "    def encode_frequency(self):\n",
    "        self.df['subvillage_funder_installer'] = (\n",
    "            self.df['subvillage'].astype(str) + \"_\" + self.df['funder_installer_pair_grouped'].astype(str)\n",
    "        )\n",
    "        freq_map = self.df['subvillage_funder_installer'].value_counts().to_dict()\n",
    "        self.df['subvillage_funder_installer_freq'] = self.df['subvillage_funder_installer'].map(freq_map)\n",
    "\n",
    "    def impute_construction_year(self):\n",
    "        self.df['construction_year'] = self.df['construction_year'].replace(0, np.nan)\n",
    "        self.df['unknown_construction_year'] = self.df['construction_year'].isna()\n",
    "\n",
    "        med_fi = self.df.groupby('subvillage_funder_installer')['construction_year'].median()\n",
    "        self.df = self.df.merge(med_fi.rename('median_fi'), on='subvillage_funder_installer', how='left')\n",
    "        self.df['construction_year'].fillna(self.df['median_fi'], inplace=True)\n",
    "        self.df.drop(columns='median_fi', inplace=True)\n",
    "\n",
    "        med_region = self.df.groupby('region')['construction_year'].median()\n",
    "        self.df = self.df.merge(med_region.rename('median_region'), on='region', how='left')\n",
    "        self.df['construction_year'].fillna(self.df['median_region'], inplace=True)\n",
    "        self.df.drop(columns='median_region', inplace=True)\n",
    "\n",
    "        self.df['construction_year'].fillna(self.df['construction_year'].median(), inplace=True)\n",
    "\n",
    "    def calculate_pump_age(self):\n",
    "        self.df['date_recorded'] = pd.to_datetime(self.df['date_recorded'], errors='coerce')\n",
    "        self.df['pump_age'] = self.df.apply(\n",
    "            lambda row: max(row['date_recorded'].year - row['construction_year'], 0)\n",
    "            if not pd.isna(row['date_recorded']) and not pd.isna(row['construction_year']) else np.nan,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    def compute_water_scores(self):\n",
    "        quantity_map = {'dry': 1, 'insufficient': 2, 'seasonal': 3, 'enough': 4, 'unknown': 1}\n",
    "        quality_map = {\n",
    "            'fluoride abandoned': 0, 'salty abandoned': 0,\n",
    "            'fluoride': 1, 'salty': 1,\n",
    "            'coloured': 2, 'milky': 2,\n",
    "            'soft': 3, 'unknown': 0\n",
    "        }\n",
    "        self.df['water_quantity_score'] = self.df['quantity'].map(quantity_map).fillna(1).astype(int)\n",
    "        self.df['water_quality_score'] = self.df['water_quality'].map(quality_map).fillna(0).astype(int)\n",
    "        self.df['water_availability_index'] = self.df['water_quantity_score'] / self.df['population'].replace(0, np.nan)\n",
    "        self.df['water_safety_sum'] = self.df['water_quality_score'] + self.df['water_quantity_score']\n",
    "\n",
    "    def impute_population_by_median(self):\n",
    "        self.df['population'] = self.df['population'].replace(0, pd.NA)\n",
    "        self.df['gps_height_bin'] = pd.qcut(self.df['gps_height'], q=5, duplicates='drop')\n",
    "        self.df['lat_lon_bin'] = pd.qcut(self.df['latitude'] * self.df['longitude'], q=10, duplicates='drop')\n",
    "\n",
    "        groupings = [\n",
    "            ['region', 'water_quantity_score', 'waterpoint_type'],\n",
    "            ['region', 'gps_height_bin'],\n",
    "            ['region', 'lat_lon_bin'],\n",
    "            ['region', 'waterpoint_type'],\n",
    "            ['region']\n",
    "        ]\n",
    "        for group in groupings:\n",
    "            med = self.df.groupby(group)['population'].transform('median')\n",
    "            self.df['population'] = self.df['population'].fillna(med)\n",
    "\n",
    "        self.df['population'] = self.df['population'].fillna(self.df['population'].median())\n",
    "\n",
    "    def impute_gps_height_by_ward(self):\n",
    "        self.df.loc[self.df['gps_height'] <= 0, 'gps_height'] = np.nan\n",
    "        self.df['gps_height'] = self.df.groupby('ward')['gps_height'].transform(lambda x: x.fillna(x.median()))\n",
    "        self.df['gps_height'].fillna(self.df['gps_height'].median(), inplace=True)\n",
    "\n",
    "    def generate_interaction_features(self):\n",
    "        self.df['lat_bin'] = (self.df['latitude'] * 10).round(0)\n",
    "        self.df['lon_bin'] = (self.df['longitude'] * 10).round(0)\n",
    "        self.df['location_bucket'] = self.df['lat_bin'].astype(str) + \"_\" + self.df['lon_bin'].astype(str)\n",
    "        self.df['lat_long_interaction'] = self.df['latitude'] + self.df['longitude']\n",
    "        self.df['pumpage_safety_inter'] = self.df['pump_age'] * self.df['water_safety_sum']\n",
    "        self.df['extraction_type_class'], _ = pd.factorize(self.df['extraction_type_class'])\n",
    "        self.df['quantity_extraction_inter'] = self.df['water_quantity_score'] * self.df['extraction_type_class']\n",
    "\n",
    "    def run_all(self):\n",
    "        self.impute_coords_from_shapefile()\n",
    "        self.impute_subvillage_by_location()\n",
    "        self.combine_funder_installer_grouped()\n",
    "        self.encode_frequency()\n",
    "        self.impute_construction_year()\n",
    "        self.calculate_pump_age()\n",
    "        self.compute_water_scores()\n",
    "        self.impute_population_by_median()\n",
    "        self.impute_gps_height_by_ward()\n",
    "        self.generate_interaction_features()\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../data/processed/Merged_Training_Set.csv\")\n",
    "\n",
    "preprocessor = WaterPumpPreprocessor(\n",
    "    raw_df,\n",
    "    gadm_path=\"../data/external/gadm41_TZA_shp/gadm41_TZA_3.shp\"\n",
    ")\n",
    "final_df = preprocessor.run_all()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
