{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modular Python code:\n",
    "\n",
    "- Handles imbalanced classes using StratifiedKFold and f1_score.\n",
    "- Compares RandomForestClassifier and XGBClassifier.\n",
    "- Iteratively drops or alters one feature at a time and tracks the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ens_df = pd.read_csv(\"../data/processed/imputed_latlon_fI_pumpage_pop_gps.csv\")\n",
    "\n",
    "X = cat_train_df.drop(['status_group','id'], axis=1)\n",
    "y = cat_train_df['status_group']\n",
    "\n",
    "print(ens_df.shape)\n",
    "print(ens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, n_splits=5, random_state=42):\n",
    "    \"\"\"Evaluate Random Forest and XGBoost using StratifiedKFold and F1-macro.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    rf_scores, xgb_scores = [], []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "        xgb = XGBClassifier(n_estimators=100, random_state=random_state, n_jobs=-1, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        rf_preds = rf.predict(X_val)\n",
    "        xgb_preds = xgb.predict(X_val)\n",
    "\n",
    "        rf_scores.append(f1_score(y_val, rf_preds, average='macro'))\n",
    "        xgb_scores.append(f1_score(y_val, xgb_preds, average='macro'))\n",
    "\n",
    "    return np.mean(rf_scores), np.mean(xgb_scores)\n",
    "\n",
    "\n",
    "def feature_impact_analysis(X, y):\n",
    "    \"\"\"Run feature ablation: remove each feature one at a time and evaluate models.\"\"\"\n",
    "    baseline_rf, baseline_xgb = evaluate_models(X, y)\n",
    "    print(f\"Baseline RF F1: {baseline_rf:.4f}, XGB F1: {baseline_xgb:.4f}\")\n",
    "    \n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for col in tqdm(X.columns, desc=\"Testing each feature\"):\n",
    "        X_dropped = X.drop(columns=[col])\n",
    "        rf_score, xgb_score = evaluate_models(X_dropped, y)\n",
    "        results['feature'].append(col)\n",
    "        results['rf_f1'].append(rf_score)\n",
    "        results['xgb_f1'].append(xgb_score)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['rf_diff'] = df_results['rf_f1'] - baseline_rf\n",
    "    df_results['xgb_diff'] = df_results['xgb_f1'] - baseline_xgb\n",
    "    return df_results.sort_values(by='rf_diff')  # or 'xgb_diff'\n",
    "\n",
    "# Example usage:\n",
    "# df_results = feature_impact_analysis(X, y)\n",
    "# print(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
